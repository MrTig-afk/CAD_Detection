# -*- coding: utf-8 -*-
"""CAD_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K_E4Q2XjJAbsRVnCOMJopGxHiEATf0yg
"""

import sklearn.datasets
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import f1_score
from sklearn.model_selection import KFold

from google.colab import drive
drive.mount('/content/drive')

path="/content/drive/MyDrive/Final Project/Final Project/Dataset/heart.csv"
data=  pd.read_csv(path)

data

data.isnull().sum()

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))

scatter_age_sex = sns.scatterplot(x='age', y='sex', data=data, ax=axes[0, 0], hue='sex', palette={0: 'blue', 1: 'red'})
scatter_age_sex.set_xlabel('Age')
scatter_age_sex.set_ylabel('Sex (0: Female, 1: Male)')
scatter_age_sex.set_title('Scatter Plot of Age vs Sex')
scatter_age_sex.spines[['top', 'right']].set_visible(False)
scatter_age_sex.legend(loc='center left')

data['thal'].plot(kind='hist', bins=20, title='Thal', ax=axes[0, 1])
axes[0, 1].spines[['top', 'right']].set_visible(False)

data['trestbps'].plot(kind='hist', bins=20, title='trestbps', ax=axes[1, 0])
axes[1, 0].spines[['top', 'right']].set_visible(False)

scatter_cp_trestbps = sns.scatterplot(x='cp', y='trestbps', data=data, ax=axes[1, 1], hue='cp', palette='viridis')
scatter_cp_trestbps.set_xlabel('Chest Pain Type (cp)')
scatter_cp_trestbps.set_ylabel('trestbps')
scatter_cp_trestbps.set_title('Scatter Plot of cp vs trestbps')

plt.tight_layout()
plt.show()

print(data.head())
print(data.shape)
print(data['target'].value_counts())

"""Train Test Split"""

newdata=data.dropna(axis=0,how='any')
print(newdata.shape)
X = data.drop('target', axis=1)
Y = data['target']
Y=pd.DataFrame(Y)
print(X.shape)
print(Y.shape)
print(Y)
type(X)
type(Y)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify = Y, random_state=1)
print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)
print(X_train.mean(), X_test.mean(), X.mean())

"""Support Vector Classifier- Linear"""

from sklearn.metrics import f1_score
from sklearn.model_selection import KFold

svclassifier = SVC(kernel='linear')
svclassifier.fit(X_train, np.ravel(Y_train))
y_pred = svclassifier.predict(X_test)

# Metrics before k-fold cross-validation
accuracy_before = accuracy_score(Y_test, y_pred)
precision_before = precision_score(Y_test, y_pred)
recall_before = recall_score(Y_test, y_pred)
f1_before = f1_score(Y_test, y_pred)

print("Metrics Before K-Fold Cross-Validation for SVM-linear:")
print("Accuracy =", accuracy_before * 100)
print("Precision =", precision_before * 100)
print("Recall =", recall_before * 100)
print("F1 =", f1_before)

print("\nBoosting Classifier with K-Fold Validation")
boostclassifier = AdaBoostClassifier(base_estimator=svclassifier, algorithm="SAMME", n_estimators=150)

def run_kfold(clf):
    kf = KFold(10, shuffle=False)
    outcomes_accuracy = []
    outcomes_precision = []
    outcomes_recall = []
    outcomes_f1 = []
    fold = 0

    for train_index, test_index in kf.split(X):
        fold += 1
        X_train_fold, X_test_fold = X.values[train_index], X.values[test_index]
        y_train_fold, y_test_fold = Y.values[train_index], Y.values[test_index]
        clf.fit(X_train_fold, np.ravel(y_train_fold))
        predictions = clf.predict(X_test_fold)

        accuracy_fold = accuracy_score(y_test_fold, predictions)
        precision_fold = precision_score(y_test_fold, predictions)
        recall_fold = recall_score(y_test_fold, predictions)
        f1_fold = f1_score(y_test_fold, predictions)

        outcomes_accuracy.append(accuracy_fold)
        outcomes_precision.append(precision_fold)
        outcomes_recall.append(recall_fold)
        outcomes_f1.append(f1_fold)

        print("Fold {0} accuracy: {1}".format(fold, accuracy_fold))
        print("Fold {0} precision: {1}".format(fold, precision_fold))
        print("Fold {0} recall: {1}".format(fold, recall_fold))
        print("Fold {0} f1: {1}".format(fold, f1_fold))

    # Metrics after k-fold cross-validation by applying K fold to the entire data in X_test
    y_pred_after_cv = clf.predict(X_test)
    accuracy_after = accuracy_score(Y_test, y_pred_after_cv)
    precision_after = precision_score(Y_test, y_pred_after_cv)
    recall_after = recall_score(Y_test, y_pred_after_cv)
    f1_after = f1_score(Y_test, y_pred_after_cv)

    print("\nMetrics After K-Fold Cross-Validation for SVM-linear:")
    print("Accuracy =", accuracy_after * 100)
    print("Precision =", precision_after * 100)
    print("Recall =", recall_after * 100)
    print("F1 =", f1_after)

    # Classification report after k-fold cross-validation
    print("\nClassification Report After K-Fold Cross-Validation:")
    print(classification_report(Y_test, y_pred_after_cv))


run_kfold(boostclassifier)

"""KNN with 1 neighbours

"""

knnclassifier = KNeighborsClassifier(n_neighbors=1)
knnclassifier.fit(X_train, np.ravel(Y_train))
y_pred_before = knnclassifier.predict(X_test)

# Metrics before k-fold cross-validation
accuracy_before = accuracy_score(Y_test, y_pred_before)
precision_before = precision_score(Y_test, y_pred_before)
recall_before = recall_score(Y_test, y_pred_before)
f1_before = f1_score(Y_test, y_pred_before)

print("Metrics Before K-Fold Cross-Validation for KNN-1 neighbor:")
print("Accuracy =", accuracy_before * 100)
print("Precision =", precision_before * 100)
print("Recall =", recall_before * 100)
print("F1 =", f1_before)

print("\nBagging Classifier with K-Fold Validation")
baggclassifier = BaggingClassifier(base_estimator=knnclassifier, n_estimators=300)

def run_kfold(clf):
    kf = KFold(10, shuffle=False)
    outcomes_accuracy = []
    outcomes_precision = []
    outcomes_recall = []
    outcomes_f1 = []
    fold = 0

    for train_index, test_index in kf.split(X):
        fold += 1
        X_train_fold, X_test_fold = X.values[train_index], X.values[test_index]
        y_train_fold, y_test_fold = Y.values[train_index], Y.values[test_index]

        clf.fit(X_train_fold, np.ravel(y_train_fold))
        predictions = clf.predict(X_test_fold)

        accuracy_fold = accuracy_score(y_test_fold, predictions)
        precision_fold = precision_score(y_test_fold, predictions)
        recall_fold = recall_score(y_test_fold, predictions)
        f1_fold = f1_score(y_test_fold, predictions)

        outcomes_accuracy.append(accuracy_fold)
        outcomes_precision.append(precision_fold)
        outcomes_recall.append(recall_fold)
        outcomes_f1.append(f1_fold)

        print("Fold {0} accuracy: {1}".format(fold, accuracy_fold))
        print("Fold {0} precision: {1}".format(fold, precision_fold))
        print("Fold {0} recall: {1}".format(fold, recall_fold))
        print("Fold {0} f1: {1}".format(fold, f1_fold))

    # Metrics after k-fold cross-validation
    y_pred_after_cv = clf.predict(X_test)
    accuracy_after = accuracy_score(Y_test, y_pred_after_cv)
    precision_after = precision_score(Y_test, y_pred_after_cv)
    recall_after = recall_score(Y_test, y_pred_after_cv)
    f1_after = f1_score(Y_test, y_pred_after_cv)

    print("\nMetrics After K-Fold Cross-Validation for KNN-1 neighbor:")
    print("Accuracy =", accuracy_after * 100)
    print("Precision =", precision_after * 100)
    print("Recall =", recall_after * 100)
    print("F1 =", f1_after)

    # Classification report after k-fold cross-validation
    print("\nClassification Report After K-Fold Cross-Validation:")
    print(classification_report(Y_test, y_pred_after_cv))


run_kfold(baggclassifier)

"""Decision Tree"""

dtclassifier = DecisionTreeClassifier()
dtclassifier.fit(X_train, np.ravel(Y_train))
y_pred_before = dtclassifier.predict(X_test)

# Metrics before k-fold cross-validation
accuracy_before = accuracy_score(Y_test, y_pred_before)
precision_before = precision_score(Y_test, y_pred_before)
recall_before = recall_score(Y_test, y_pred_before)
f1_before = f1_score(Y_test, y_pred_before)

print("Metrics Before K-Fold Cross-Validation for Decision Tree:")
print("Accuracy =", accuracy_before * 100)
print("Precision =", precision_before * 100)
print("Recall =", recall_before * 100)
print("F1 =", f1_before)

print("\nBoosting Classifier with K-Fold Validation")
boostclassifier = AdaBoostClassifier(base_estimator=dtclassifier, algorithm="SAMME", n_estimators=50)

def run_kfold(clf):
    kf = KFold(10, shuffle=False)
    outcomes_accuracy = []
    outcomes_precision = []
    outcomes_recall = []
    outcomes_f1 = []
    fold = 0

    for train_index, test_index in kf.split(X):
        fold += 1
        X_train_fold, X_test_fold = X.values[train_index], X.values[test_index]
        y_train_fold, y_test_fold = Y.values[train_index], Y.values[test_index]

        clf.fit(X_train_fold, np.ravel(y_train_fold))
        predictions = clf.predict(X_test_fold)

        accuracy_fold = accuracy_score(y_test_fold, predictions)
        precision_fold = precision_score(y_test_fold, predictions)
        recall_fold = recall_score(y_test_fold, predictions)
        f1_fold = f1_score(y_test_fold, predictions)

        outcomes_accuracy.append(accuracy_fold)
        outcomes_precision.append(precision_fold)
        outcomes_recall.append(recall_fold)
        outcomes_f1.append(f1_fold)

        print("Fold {0} accuracy: {1}".format(fold, accuracy_fold))
        print("Fold {0} precision: {1}".format(fold, precision_fold))
        print("Fold {0} recall: {1}".format(fold, recall_fold))
        print("Fold {0} f1: {1}".format(fold, f1_fold))

    # Metrics after k-fold cross-validation
    y_pred_after_cv = clf.predict(X_test)
    accuracy_after = accuracy_score(Y_test, y_pred_after_cv)
    precision_after = precision_score(Y_test, y_pred_after_cv)
    recall_after = recall_score(Y_test, y_pred_after_cv)
    f1_after = f1_score(Y_test, y_pred_after_cv)

    print("\nMetrics After K-Fold Cross-Validation for Decision Tree:")
    print("Accuracy =", accuracy_after * 100)
    print("Precision =", precision_after * 100)
    print("Recall =", recall_after * 100)
    print("F1 =", f1_after)

    # Classification report after k-fold cross-validation
    print("\nClassification Report After K-Fold Cross-Validation:")
    print(classification_report(Y_test, y_pred_after_cv))

run_kfold(boostclassifier)

"""Logistic Regression"""

warnings.filterwarnings("ignore")

lcclassifier = LogisticRegression(C=1.0, max_iter=100, penalty='l2')


lcclassifier.fit(X_train, np.ravel(Y_train))
y_pred_before = lcclassifier.predict(X_test)

# Metrics before k-fold cross-validation
accuracy_before = accuracy_score(Y_test, y_pred_before)
precision_before = precision_score(Y_test, y_pred_before)
recall_before = recall_score(Y_test, y_pred_before)
f1_before = f1_score(Y_test, y_pred_before)

print("Metrics Before K-Fold Cross-Validation for Logistic Regression:")
print("Accuracy =", accuracy_before * 100)
print("Precision =", precision_before * 100)
print("Recall =", recall_before * 100)
print("F1 =", f1_before)

print("\nBoosting Classifier with K-Fold Validation")
boostclassifier = AdaBoostClassifier(base_estimator=lcclassifier, algorithm="SAMME", n_estimators=150 )

def run_kfold(clf):
    kf = KFold(10, shuffle=False)
    outcomes_accuracy = []
    outcomes_precision = []
    outcomes_recall = []
    outcomes_f1 = []
    fold = 0

    for train_index, test_index in kf.split(X):
        fold += 1
        X_train_fold, X_test_fold = X.values[train_index], X.values[test_index]
        y_train_fold, y_test_fold = Y.values[train_index], Y.values[test_index]

        clf.fit(X_train_fold, np.ravel(y_train_fold))
        predictions = clf.predict(X_test_fold)

        accuracy_fold = accuracy_score(y_test_fold, predictions)
        precision_fold = precision_score(y_test_fold, predictions)
        recall_fold = recall_score(y_test_fold, predictions)
        f1_fold = f1_score(y_test_fold, predictions)

        outcomes_accuracy.append(accuracy_fold)
        outcomes_precision.append(precision_fold)
        outcomes_recall.append(recall_fold)
        outcomes_f1.append(f1_fold)

        print("Fold {0} accuracy: {1}".format(fold, accuracy_fold))
        print("Fold {0} precision: {1}".format(fold, precision_fold))
        print("Fold {0} recall: {1}".format(fold, recall_fold))
        print("Fold {0} f1: {1}".format(fold, f1_fold))

    # Metrics after k-fold cross-validation
    y_pred_after_cv = clf.predict(X_test)
    accuracy_after = accuracy_score(Y_test, y_pred_after_cv)
    precision_after = precision_score(Y_test, y_pred_after_cv)
    recall_after = recall_score(Y_test, y_pred_after_cv)
    f1_after = f1_score(Y_test, y_pred_after_cv)

    print("\nMetrics After K-Fold Cross-Validation for Logistic Regression:")
    print("Accuracy =", accuracy_after * 100)
    print("Precision =", precision_after * 100)
    print("Recall =", recall_after * 100)
    print("F1 =", f1_after)

    # Classification report after k-fold cross-validation
    print("\nClassification Report After K-Fold Cross-Validation:")
    print(classification_report(Y_test, y_pred_after_cv))

run_kfold(boostclassifier)

"""Random Forest"""

# Random Forest Classifier
rfclassifier = RandomForestClassifier()
rfclassifier.fit(X_train, np.ravel(Y_train))
y_pred_rf = rfclassifier.predict(X_test)

# Metrics for Random Forest Classifier
accuracy_rf = accuracy_score(Y_test, y_pred_rf)
precision_rf = precision_score(Y_test, y_pred_rf)
recall_rf = recall_score(Y_test, y_pred_rf)
f1_rf = 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
cm_rf = confusion_matrix(Y_test, y_pred_rf)
sensitivity_rf = cm_rf[0, 0] / (cm_rf[0, 0] + cm_rf[0, 1])
specificity_rf = cm_rf[1, 0] / (cm_rf[1, 0] + cm_rf[1, 1])

print("Random Forest Classifier Metrics for Random Forest:")
print("Accuracy =", accuracy_rf * 100)
print("Precision =", precision_rf * 100)
print("Recall =", recall_rf * 100)
print("F1 =", f1_rf)
print("Sensitivity =", sensitivity_rf)
print("Specificity =", specificity_rf)

# Boosting Classifier with Random Forest
boostclassifier_rf = AdaBoostClassifier(base_estimator=rfclassifier, algorithm="SAMME", n_estimators=150)

def run_kfold(clf):
    kf = KFold(10, shuffle=False)
    outcomes_accuracy = []
    outcomes_precision = []
    outcomes_recall = []
    outcomes_f1 = []
    fold = 0

    for train_index, test_index in kf.split(X):
        fold += 1
        X_train_fold, X_test_fold = X.values[train_index], X.values[test_index]
        y_train_fold, y_test_fold = Y.values[train_index], Y.values[test_index]
        clf.fit(X_train_fold, np.ravel(y_train_fold))
        predictions_fold = clf.predict(X_test_fold)

        accuracy_fold = accuracy_score(y_test_fold, predictions_fold)
        precision_fold = precision_score(y_test_fold, predictions_fold)
        recall_fold = recall_score(y_test_fold, predictions_fold)
        f1_fold = 2 * (precision_fold * recall_fold) / (precision_fold + recall_fold)

        outcomes_accuracy.append(accuracy_fold)
        outcomes_precision.append(precision_fold)
        outcomes_recall.append(recall_fold)
        outcomes_f1.append(f1_fold)

        print("Fold {0} accuracy: {1}".format(fold, accuracy_fold))
        print("Fold {0} precision: {1}".format(fold, precision_fold))
        print("Fold {0} recall: {1}".format(fold, recall_fold))
        print("Fold {0} f1: {1}".format(fold, f1_fold))

    # Metrics after k-fold cross-validation
    y_pred_after_cv = clf.predict(X_test)
    accuracy_after = accuracy_score(Y_test, y_pred_after_cv)
    precision_after = precision_score(Y_test, y_pred_after_cv)
    recall_after = recall_score(Y_test, y_pred_after_cv)
    f1_after = 2 * (precision_after * recall_after) / (precision_after + recall_after)

    print("\nMetrics After K-Fold Cross-Validation for Random Forest:")
    print("Accuracy =", accuracy_after * 100)
    print("Precision =", precision_after * 100)
    print("Recall =", recall_after * 100)
    print("F1 =", f1_after)

    # Classification report after k-fold cross-validation
    print("\nClassification Report After K-Fold Cross-Validation:")
    print(classification_report(Y_test, y_pred_after_cv))


run_kfold(boostclassifier_rf)

classifiers = ['Support Vector (kernel=linear)', 'K-Nearest Neighbors', 'Decision Tree', 'Logistic Regression', 'Random Forest']
accuracies = [84.42, 99.02, 100, 84.74, 100]

colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd', '#8c564b']

sorted_classifiers, sorted_accuracies = zip(*sorted(zip(classifiers, accuracies), key=lambda x: x[1]))

fig, ax = plt.subplots(figsize=(25, 6))
bars = ax.barh(sorted_classifiers, sorted_accuracies, color=colors, height=0.5)

for bar, value in zip(bars, sorted_accuracies):
    ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height() / 2 - 0.10, f'{value:.2f}%', va='center_baseline', fontsize=10)

ax.set_xlabel("Accuracy (%)")
ax.set_title("Classifiers and their Accuracies")

plt.show()